{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNLfsr38dvF0lHJHqLvK5rZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NickFury89/Car-race-game/blob/master/%D0%A1%D0%B5%D1%80%D0%B2%D0%B8%D1%81_%D0%BC%D0%BE%D0%BD%D0%B8%D1%82%D0%BE%D1%80%D0%B0_%D0%BA%D0%BD%D0%B8%D0%B3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bеб-скрейпер на Python для сбора метаданных и текстов книг из онлайн-магазинов и библиотек:**"
      ],
      "metadata": {
        "id": "r_TC_MjcFgcu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdB9Nb1k_nL6"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def scrape_book(url):\n",
        "    \n",
        "    # Отправляем GET-запрос на страницу с книгой\n",
        "    \n",
        "    response = requests.get(url)\n",
        "    \n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Извлекаем метаданные книги\n",
        "    \n",
        "    title = soup.find('h1', {'class': 'book-title'}).text.strip()\n",
        "    \n",
        "    author = soup.find('div', {'class': 'book-author'}).find('a').text.strip()\n",
        "    \n",
        "    genre = soup.find('span', {'class': 'genre'}).find('a').text.strip()\n",
        "    \n",
        "    description = soup.find('div', {'class': 'book-annotation'}).text.strip()\n",
        "    \n",
        "    cover_url = soup.find('img', {'class': 'book-image'})['src']\n",
        "\n",
        "    # Извлекаем текст книги\n",
        "    \n",
        "    book_text = ''\n",
        "    \n",
        "    for page_num in range(1, 101):\n",
        "        \n",
        "        page_url = f'{url}/chapter-{page_num}'\n",
        "        \n",
        "        response = requests.get(page_url)\n",
        "        \n",
        "        page_soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        \n",
        "        page_text = page_soup.find('div', {'class': 'reader-container'}).text.strip()\n",
        "        \n",
        "        book_text += page_text + '\\n'\n",
        "\n",
        "    # Возвращаем словарь с метаданными и текстом книги\n",
        "    \n",
        "    return {\n",
        "        \n",
        "        'title': title,\n",
        "        \n",
        "        'author': author,\n",
        "        \n",
        "        'genre': genre,\n",
        "        \n",
        "        'description': description,\n",
        "        \n",
        "        'cover_url': cover_url,\n",
        "        \n",
        "        'book_text': book_text,\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Код обработки естественного языка для извлечения функций библиотеки из текста книг"
      ],
      "metadata": {
        "id": "4c3SKkAtFsiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def extract_library_functions(book_text):\n",
        "    \n",
        "    # Разбиваем текст книги на предложения и токены\n",
        "    \n",
        "    sentences = sent_tokenize(book_text)\n",
        "    \n",
        "    tokens = word_tokenize(book_text.lower())\n",
        "\n",
        "    # Определяем список стоп-слов и лемматизатор\n",
        "    \n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    \n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "    # Извлекаем глаголы, прилагательные и существительные\n",
        "    \n",
        "    pos_tags = nltk.pos_tag(tokens)\n",
        "    \n",
        "    verbs = [lemmatizer.lemmatize(word) for word, tag in pos_tags if tag.startswith('VB')]\n",
        "    \n",
        "    adjectives = [lemmatizer.lemmatize(word) for word, tag in pos_tags if tag.startswith('JJ')]\n",
        "    \n",
        "    nouns = [lemmatizer.lemmatize(word) for word, tag in pos_tags if tag.startswith('NN')]\n",
        "\n",
        "    # Отфильтровываем стоп-слова и возвращаем уникальные значения\n",
        "    \n",
        "    verbs = list(set(verbs) - stop_words)\n",
        "    \n",
        "    adjectives = list(set(adjectives) - stop_words)\n",
        "    \n",
        "    nouns = list(set(nouns) - stop_words)\n",
        "\n",
        "    # Возвращаем словарь с глаголами, прилагательными и существительными\n",
        "    \n",
        "    return {\n",
        "        \n",
        "        'verbs': verbs,\n",
        "        \n",
        "        'adjectives': adjectives,\n",
        "        \n",
        "        'nouns': nouns,\n",
        "    }\n"
      ],
      "metadata": {
        "id": "XzAw_CJxAbHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Машинное обучение"
      ],
      "metadata": {
        "id": "fTuU6lAEBNNB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "import joblib\n",
        "import sqlite3\n",
        "\n",
        "# Подключаемся к базе данных и создаем таблицу для результатов\n",
        "conn = sqlite3.connect('books.db')\n",
        "c = conn.cursor()\n",
        "c.execute('''CREATE TABLE IF NOT EXISTS model_results \n",
        "             (model_name text, accuracy real)''')\n",
        "\n",
        "# Загружаем данные и разделяем их на обучающую и тестовую выборки\n",
        "data = pd.read_csv('books_data.csv')\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['text'], data['genre'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Обучаем модели на обучающей выборке\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Naive Bayes': MultinomialNB(),\n",
        "}\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Оцениваем точность моделей на тестовой выборке\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    # Сохраняем модели и результаты в базу данных\n",
        "    joblib.dump(model, f'{name}.joblib')\n",
        "    c.execute(\"INSERT INTO model_results VALUES (?, ?)\", (name, accuracy))\n",
        "\n",
        "# Сохраняем изменения в базе данных и закрываем соединение\n",
        "conn.commit()\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "SCvk1ZEBCOC8",
        "outputId": "425838ef-d63d-4540-879e-304634ac742a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-0dd13f3c337d>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Загружаем данные и разделяем их на обучающую и тестовую выборки\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'books_data.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'genre'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'books_data.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# База данных"
      ],
      "metadata": {
        "id": "TRIqr_pmDO--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CREATE TABLE books (\n",
        "    id INTEGER PRIMARY KEY,\n",
        "    title TEXT,\n",
        "    author TEXT,\n",
        "    genre TEXT,\n",
        "    language TEXT,\n",
        "    publication_date TEXT,\n",
        "    publisher TEXT,\n",
        "    text TEXT,\n",
        "    features TEXT,\n",
        "    analysis_result TEXT\n",
        ");\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "HzEhgAaRDRFi",
        "outputId": "4ce9303c-ec96-4f35-c949-480bacc6b460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-22e0cacf5565>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    CREATE TABLE books (\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Чтобы сохранить данные в базе данных, мы можем использовать трафик sqlite3в Python. Вот пример кода, который добавляет данные в таблицу books:"
      ],
      "metadata": {
        "id": "jhJWF_TPDZU2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlite3\n",
        "\n",
        "conn = sqlite3.connect('books.db')\n",
        "cursor = conn.cursor()\n",
        "\n",
        "# Добавляем данные в таблицу\n",
        "cursor.execute(\"INSERT INTO books (title, author, genre, language, publication_date, publisher, text, features, analysis_result) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\", (title, author, genre, language, publication_date, publisher, text, features, analysis_result))\n",
        "conn.commit()\n",
        "\n",
        "# Закрываем соединение с базой данных\n",
        "conn.close()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "GYMZi34EDd9E",
        "outputId": "be12512c-8293-41b3-fc33-1f33cc7905c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d4e96231aaed>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Добавляем данные в таблицу\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"INSERT INTO books (title, author, genre, language, publication_date, publisher, text, features, analysis_result) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublication_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpublisher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalysis_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'title' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для создания внешнего вида для поиска книг по созданию параметров и страниц для просмотра информации о книгах и их оценках можно использовать веб-фреймворк, например Flask. Ниже представлен пример кода для создания простого веб-приложения с возможностью поиска книг по жанру и просмотра информации о книгах:\n"
      ],
      "metadata": {
        "id": "NgJNh1aXD6WN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, render_template, request\n",
        "import sqlite3\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return render_template('home.html')\n",
        "\n",
        "@app.route('/search', methods=['GET', 'POST'])\n",
        "def search():\n",
        "    if request.method == 'POST':\n",
        "        genre = request.form['genre']\n",
        "        conn = sqlite3.connect('books.db')\n",
        "        c = conn.cursor()\n",
        "        c.execute(\"SELECT * FROM books WHERE genre=?\", (genre,))\n",
        "        books = c.fetchall()\n",
        "        conn.close()\n",
        "        return render_template('search_results.html', books=books)\n",
        "    else:\n",
        "        return render_template('search.html')\n",
        "\n",
        "@app.route('/book/<int:book_id>')\n",
        "def book(book_id):\n",
        "    conn = sqlite3.connect('books.db')\n",
        "    c = conn.cursor()\n",
        "    c.execute(\"SELECT * FROM books WHERE id=?\", (book_id,))\n",
        "    book = c.fetchone()\n",
        "    c.execute(\"SELECT * FROM ratings WHERE book_id=?\", (book_id,))\n",
        "    ratings = c.fetchall()\n",
        "    conn.close()\n",
        "    return render_template('book.html', book=book, ratings=ratings)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbcoonPhEBPd",
        "outputId": "fca8b6aa-24ed-4947-fe4f-8b17b481d012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Развернуть систему на облачном сервисе для обеспечения масштабируемости и отказоустойчивости. используйте облачные сервисы для хранения данных и файлы с шаблонами машинного обучения. Настроены высокие масштабы и мониторинг состояния системы."
      ],
      "metadata": {
        "id": "7DBB80EhFRbk"
      }
    }
  ]
}